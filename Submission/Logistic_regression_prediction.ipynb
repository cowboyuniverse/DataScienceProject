{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode the feature matrix for the training data using get_dummies logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 2nd json object has total ingredients: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine_train_dataframe = pd.read_json('train.json')\n",
    "cuisine_test_dataframe = pd.read_json('test.json')\n",
    "\n",
    "feature_cols = ['ingredients']\n",
    "\n",
    "X = cuisine_train_dataframe[feature_cols]\n",
    "\n",
    "Y = cuisine_test_dataframe[['ingredients']]\n",
    "\n",
    "# convert array of strings for each json object to array of 1's and zeros by finding the number of unique ingredients \n",
    "#in all arrays \n",
    "# and creating that many columns and looping through all strings in the arrays and finding their index and setting it to 1 \n",
    "\n",
    "keys = set()\n",
    "\n",
    "for ing_list in X['ingredients']:\n",
    "    for ing in ing_list:\n",
    "        keys.add(ing)\n",
    "\n",
    "for ing_list in Y['ingredients']:\n",
    "    for ing in ing_list:\n",
    "        keys.add(ing)  \n",
    "        \n",
    "             \n",
    "encoded = np.zeros(len(X) * len(keys)).reshape((len(X), len(keys)))\n",
    "    \n",
    "key_list = list(keys)\n",
    "\n",
    "my_index = 0\n",
    "\n",
    "for l in X['ingredients']:\n",
    "    for item in l:\n",
    "        index = key_list.index(item)\n",
    "        encoded[my_index][index] = 1\n",
    "    my_index += 1\n",
    "\n",
    "# feature matrix is now 2d array of 1's and 0's, representing the ingredients\n",
    "X = np.array(encoded)\n",
    "\n",
    "print(\"the 2nd json object has total ingredients: \")\n",
    "np.count_nonzero(X[1] == 1)\n",
    "# 11 columns are set to 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode the feature matrix for the testing data as well using get_dummies logic, predict and save predictions in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['british' 'southern_us' 'italian' ..., 'italian' 'southern_us' 'mexican']\n",
      "\n",
      " Probabilities of predictions: \n",
      "[[  8.88667769e-03   2.96907673e-01   1.78364613e-03 ...,   1.30625557e-02\n",
      "    3.27312959e-03   1.06281179e-03]\n",
      " [  1.16806624e-02   2.60092622e-02   3.79720530e-03 ...,   6.00519746e-03\n",
      "    1.68622929e-04   3.89337884e-03]\n",
      " [  8.37459827e-03   1.75728334e-02   6.19548056e-03 ...,   2.36637307e-02\n",
      "    1.08947086e-03   5.38955690e-03]\n",
      " ..., \n",
      " [  2.11003521e-03   1.11936441e-03   1.92147077e-02 ...,   4.61733933e-03\n",
      "    1.54914775e-03   2.56174159e-03]\n",
      " [  3.33872106e-03   2.59830309e-03   2.33588316e-02 ...,   1.52771259e-02\n",
      "    1.67781280e-04   6.60201747e-05]\n",
      " [  4.41377437e-04   2.18542649e-05   1.14077402e-05 ...,   2.53157600e-03\n",
      "    1.22719234e-04   6.81873936e-06]]\n"
     ]
    }
   ],
   "source": [
    "y = cuisine_train_dataframe['cuisine'] \n",
    "\n",
    "# encode the testing data to zeros and ones as well \n",
    "\n",
    "encoded2 = np.zeros(len(Y) * len(keys)).reshape((len(Y), len(keys)))\n",
    "    \n",
    "my_index2 = 0\n",
    "\n",
    "for l in Y['ingredients']:\n",
    "    for item in l:\n",
    "        index = key_list.index(item)\n",
    "        encoded2[my_index2][index] = 1\n",
    "    my_index2 += 1\n",
    "    \n",
    "\n",
    "Y = np.array(encoded2)\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(X, y)\n",
    "\n",
    "y_predict = logReg.predict(Y)\n",
    "print(y_predict)\n",
    "\n",
    "print(\"\\n Probabilities of predictions: \")\n",
    "\n",
    "y_predict_prob = logReg.predict_proba(Y)\n",
    "print(y_predict_prob)\n",
    "\n",
    "df1 = cuisine_test_dataframe[['id']]\n",
    "df2 = pd.DataFrame({'cuisine': y_predict})\n",
    "res = pd.concat([df1, df2], axis=1)\n",
    "res.to_csv(\"submission.csv\", encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
