{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from numpy import array\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first json object has total ingredients: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine_train_dataframe = pd.read_json('train.json')\n",
    "\n",
    "feature_cols = ['ingredients']\n",
    "\n",
    "X = cuisine_train_dataframe[feature_cols]\n",
    "\n",
    "# convert array of strings for each json object to array of 1's and zeros by finding the number of unique ingredients \n",
    "#in all arrays \n",
    "# and creating that many columns and looping through all strings in the arrays and finding their index and setting it to 1\n",
    "\n",
    "keys = set()\n",
    "\n",
    "for ing_list in X['ingredients']:\n",
    "    for ing in ing_list:\n",
    "        keys.add(ing)\n",
    "        \n",
    "# create list of same size as X of lists of zeros of size n where n = the number of unique keys         \n",
    "encoded = np.zeros(len(X) * len(keys)).reshape((len(X), len(keys)))\n",
    "\n",
    "key_list = list(keys)\n",
    "\n",
    "my_index = 0\n",
    "\n",
    "for l in X['ingredients']:\n",
    "    for item in l:\n",
    "        index = key_list.index(item)\n",
    "        encoded[my_index][index] = 1\n",
    "    my_index += 1\n",
    "    \n",
    "X = np.array(encoded)\n",
    "\n",
    "print(\"the first json object has total ingredients: \")\n",
    "np.count_nonzero(X[0] == 1)\n",
    "# 9 columns are set to 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split into 6% testing, 94% training, the higher the testing percentage the lower the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mexican' 'indian' 'indian' ..., 'thai' 'indian' 'british']\n",
      "25474         mexican\n",
      "19761          indian\n",
      "32740          indian\n",
      "34148          french\n",
      "5218      southern_us\n",
      "17371         mexican\n",
      "11160          french\n",
      "2445          mexican\n",
      "27584         spanish\n",
      "4545          mexican\n",
      "18623        japanese\n",
      "17605         mexican\n",
      "34016         british\n",
      "33127         chinese\n",
      "23296         chinese\n",
      "5254            greek\n",
      "18629        filipino\n",
      "20863     southern_us\n",
      "6095           french\n",
      "25944      vietnamese\n",
      "11350     southern_us\n",
      "17796         italian\n",
      "4274           indian\n",
      "22648         italian\n",
      "10586         mexican\n",
      "11518         italian\n",
      "28809         british\n",
      "20713         chinese\n",
      "7550          italian\n",
      "14037         chinese\n",
      "             ...     \n",
      "22463        japanese\n",
      "21739        moroccan\n",
      "14737     southern_us\n",
      "33252         italian\n",
      "17184         chinese\n",
      "33385         mexican\n",
      "22021         italian\n",
      "26956         italian\n",
      "19005         italian\n",
      "28907         italian\n",
      "13777         mexican\n",
      "25863         mexican\n",
      "23749         mexican\n",
      "12909       brazilian\n",
      "20898         italian\n",
      "1098          mexican\n",
      "9316          italian\n",
      "18242          french\n",
      "2870          chinese\n",
      "9131          mexican\n",
      "25904    cajun_creole\n",
      "15604         mexican\n",
      "1337          mexican\n",
      "29990         chinese\n",
      "25063    cajun_creole\n",
      "12340     southern_us\n",
      "16639     southern_us\n",
      "34202            thai\n",
      "27376          indian\n",
      "17510         british\n",
      "Name: cuisine, dtype: object\n",
      "\n",
      "Accuracy Logistic Regression:  0.803333333333\n",
      "\n",
      "Accuracy with cross validation: \n",
      "0.779999124111\n"
     ]
    }
   ],
   "source": [
    "# label vector\n",
    "y = cuisine_train_dataframe['cuisine'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.06, random_state=1)\n",
    "\n",
    "logReg =  LogisticRegression()\n",
    "\n",
    "logReg.fit(X_train, y_train)\n",
    "\n",
    "y_predict = logReg.predict(X_test)\n",
    "\n",
    "print(y_predict)\n",
    "print(y_test) \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(\"\\nAccuracy Logistic Regression: \", accuracy)\n",
    "\n",
    "print(\"\\nAccuracy with cross validation: \")\n",
    "\n",
    "my_logreg = LogisticRegression()\n",
    "\n",
    "accuracy_list = cross_val_score(my_logreg, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# use average of accuracy values as final result\n",
    "accuracy_cv = accuracy_list.mean()\n",
    "\n",
    "print(accuracy_cv)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of predictions\n",
      "[[  1.14431737e-03   4.65203069e-03   1.76458699e-03 ...,   8.29683823e-03\n",
      "    2.28223968e-03   1.51682870e-02]\n",
      " [  4.86825298e-03   5.82090315e-04   1.18116979e-04 ...,   1.21459255e-03\n",
      "    1.75934812e-03   1.11607164e-03]\n",
      " [  3.78464448e-02   4.24064323e-02   1.06920420e-02 ...,   5.68477649e-03\n",
      "    1.08677610e-02   9.85815869e-03]\n",
      " ..., \n",
      " [  5.76458549e-03   2.78901286e-03   3.57654118e-03 ...,   2.31651597e-03\n",
      "    7.41208456e-01   3.81310815e-02]\n",
      " [  2.27702388e-03   6.78886036e-03   2.85089419e-03 ...,   4.20931065e-03\n",
      "    2.72207628e-03   3.01935004e-03]\n",
      " [  3.65817596e-03   3.29216960e-01   7.27538543e-03 ...,   4.63288718e-02\n",
      "    3.88813384e-03   2.19082741e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilities of predictions\")\n",
    "y_predict_proba = logReg.predict_proba(X_test)\n",
    "print(y_predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.91      0.48      0.62        21\n",
      "     british       0.58      0.43      0.49        44\n",
      "cajun_creole       0.80      0.79      0.79        75\n",
      "     chinese       0.84      0.85      0.84       142\n",
      "    filipino       0.70      0.68      0.69        31\n",
      "      french       0.66      0.56      0.61       147\n",
      "       greek       0.77      0.68      0.72        59\n",
      "      indian       0.84      0.94      0.89       162\n",
      "       irish       0.86      0.60      0.70        42\n",
      "     italian       0.76      0.92      0.83       399\n",
      "    jamaican       0.91      0.74      0.82        27\n",
      "    japanese       0.87      0.67      0.76        70\n",
      "      korean       0.95      0.67      0.78        54\n",
      "     mexican       0.91      0.93      0.92       349\n",
      "    moroccan       0.91      0.78      0.84        41\n",
      "     russian       0.67      0.40      0.50        20\n",
      " southern_us       0.72      0.83      0.77       223\n",
      "     spanish       0.83      0.57      0.67        53\n",
      "        thai       0.89      0.80      0.84        95\n",
      "  vietnamese       0.78      0.67      0.72        46\n",
      "\n",
      " avg / total       0.81      0.80      0.80      2100\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10,   0,   0,   0,   1,   0,   0,   1,   0,   4,   0,   0,   0,\n",
       "          4,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,  19,   0,   0,   0,   9,   1,   2,   2,   2,   1,   0,   0,\n",
       "          1,   0,   1,   6,   0,   0,   0],\n",
       "       [  0,   0,  59,   1,   0,   1,   0,   1,   0,   3,   0,   0,   0,\n",
       "          1,   0,   0,   9,   0,   0,   0],\n",
       "       [  0,   0,   0, 120,   0,   0,   0,   2,   0,   3,   0,   3,   2,\n",
       "          5,   0,   0,   2,   0,   5,   0],\n",
       "       [  0,   0,   1,   2,  21,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          1,   0,   0,   3,   1,   0,   2],\n",
       "       [  0,   3,   2,   1,   0,  83,   2,   0,   0,  36,   1,   0,   0,\n",
       "          0,   0,   0,  18,   1,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,  40,   0,   0,  15,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   2,   1,   0, 152,   0,   0,   0,   0,   0,\n",
       "          4,   1,   0,   1,   0,   0,   0],\n",
       "       [  0,   5,   0,   0,   0,   4,   0,   1,  25,   6,   0,   0,   0,\n",
       "          0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   8,   6,   1,   0, 368,   0,   1,   0,\n",
       "          1,   1,   0,  10,   2,   0,   0],\n",
       "       [  0,   0,   1,   0,   1,   0,   0,   1,   0,   0,  20,   0,   0,\n",
       "          1,   0,   0,   3,   0,   0,   0],\n",
       "       [  0,   0,   0,   3,   0,   1,   0,  10,   0,   4,   0,  47,   0,\n",
       "          0,   0,   0,   4,   0,   0,   1],\n",
       "       [  0,   0,   0,   8,   1,   0,   0,   0,   0,   1,   0,   3,  36,\n",
       "          0,   0,   1,   4,   0,   0,   0],\n",
       "       [  0,   1,   1,   0,   0,   1,   0,   0,   1,  12,   0,   0,   0,\n",
       "        326,   0,   1,   4,   2,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   3,   0,   4,   0,   0,   0,\n",
       "          1,  32,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   2,   5,   0,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0,   8,   3,   0,   0,   0],\n",
       "       [  0,   1,  10,   0,   1,   7,   1,   1,   0,  14,   0,   0,   0,\n",
       "          3,   0,   1, 184,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   2,   1,   0,   1,  10,   0,   0,   0,\n",
       "          6,   1,   0,   1,  30,   0,   0],\n",
       "       [  0,   0,   0,   3,   1,   0,   0,   4,   0,   1,   0,   0,   0,\n",
       "          3,   0,   0,   1,   0,  76,   6],\n",
       "       [  1,   0,   0,   5,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "          2,   0,   0,   1,   0,   4,  31]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"confusion matrix\")\n",
    "\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "\n",
    "metrics.confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
